{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the sampled subset:\n",
      "                                              file  \\\n",
      "427616                     shackleton-s/sent/1912.   \n",
      "108773                    farmer-d/logistics/1066.   \n",
      "355471                  parks-j/deleted_items/202.   \n",
      "457837  stokley-c/chris_stokley/iso/client_rep/41.   \n",
      "124910               germany-c/all_documents/1174.   \n",
      "\n",
      "                                                  message         labels  \n",
      "427616  Message-ID: <21013688.1075844564560.JavaMail.e...  Non-Important  \n",
      "108773  Message-ID: <22688499.1075854130303.JavaMail.e...  Non-Important  \n",
      "355471  Message-ID: <27817771.1075841359502.JavaMail.e...  Non-Important  \n",
      "457837  Message-ID: <10695160.1075858510449.JavaMail.e...  Non-Important  \n",
      "124910  Message-ID: <27819143.1075853689038.JavaMail.e...  Non-Important  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "data_path = 'C:/Users/pooja/OneDrive/Documents/emails.csv'\n",
    "email_df = pd.read_csv(data_path)\n",
    "\n",
    "# Sample a subset of the data if needed\n",
    "n_samples = 1000\n",
    "if len(email_df) > n_samples:\n",
    "    email_df_subset = email_df.sample(n=n_samples, random_state=42)\n",
    "else:\n",
    "    email_df_subset = email_df\n",
    "\n",
    "# Add numeric and descriptive 'label' columns\n",
    "def label_email(message):\n",
    "    # Placeholder logic for labeling (e.g., check for keywords)\n",
    "    if 'urgent' in message.lower() or 'important' in message.lower():\n",
    "        return 'Important'  # Example label for important emails\n",
    "    else:\n",
    "        return 'Non-Important'  # Example label for non-important emails\n",
    "\n",
    "email_df_subset['labels'] = email_df_subset['message'].apply(label_email)\n",
    "\n",
    "# Display the first few rows of the sampled subset with the 'labels' column\n",
    "print(\"First few rows of the sampled subset:\")\n",
    "print(email_df_subset.head())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation results (before adversarial attacks):\n",
      "Validation Accuracy: 0.9466666666666667\n",
      "Validation Precision: 0.0\n",
      "Validation Recall: 0.0\n",
      "Validation F1 Score: 0.0\n",
      "\n",
      "Validation results (after adversarial attacks):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pooja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8533333333333334\n",
      "Validation Precision: 0.20833333333333334\n",
      "Validation Recall: 0.625\n",
      "Validation F1 Score: 0.3125\n",
      "\n",
      "Test results (after adversarial attacks):\n",
      "Test Accuracy: 0.84\n",
      "Test Precision: 0.24\n",
      "Test Recall: 0.5454545454545454\n",
      "Test F1 Score: 0.3333333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['email_detection_model.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Function to simulate adversarial attacks\n",
    "def simulate_adversarial_attacks(X):\n",
    "    # dd random noise to the input features\n",
    "    noisy_X = X.toarray() + np.random.normal(0, 0.007, size=X.shape)\n",
    "    return noisy_X\n",
    "\n",
    "# Extract features and labels\n",
    "X = email_df_subset['message']\n",
    "y = email_df_subset['labels']\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = vectorizer.transform(X_val)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "print(\"\\nValidation results (before adversarial attacks):\")\n",
    "y_pred_val = model.predict(X_val_tfidf)\n",
    "print(f'Validation Accuracy: {accuracy_score(y_val, y_pred_val)}')\n",
    "print(f'Validation Precision: {precision_score(y_val, y_pred_val, pos_label=\"Important\")}')\n",
    "print(f'Validation Recall: {recall_score(y_val, y_pred_val, pos_label=\"Important\")}')\n",
    "print(f'Validation F1 Score: {f1_score(y_val, y_pred_val, pos_label=\"Important\")}')\n",
    "\n",
    "# Simulate adversarial attacks on the validation set\n",
    "X_val_adversarial = simulate_adversarial_attacks(X_val_tfidf)\n",
    "\n",
    "# Evaluate the model on the perturbed validation set\n",
    "print(\"\\nValidation results (after adversarial attacks):\")\n",
    "y_pred_val_adv = model.predict(X_val_adversarial)\n",
    "print(f'Validation Accuracy: {accuracy_score(y_val, y_pred_val_adv)}')\n",
    "print(f'Validation Precision: {precision_score(y_val, y_pred_val_adv, pos_label=\"Important\")}')\n",
    "print(f'Validation Recall: {recall_score(y_val, y_pred_val_adv, pos_label=\"Important\")}')\n",
    "print(f'Validation F1 Score: {f1_score(y_val, y_pred_val_adv, pos_label=\"Important\")}')\n",
    "\n",
    "# Simulate adversarial attacks on the test set\n",
    "X_test_adversarial = simulate_adversarial_attacks(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model on the perturbed test set\n",
    "print(\"\\nTest results (after adversarial attacks):\")\n",
    "y_pred_test_adv = model.predict(X_test_adversarial)\n",
    "print(f'Test Accuracy: {accuracy_score(y_test, y_pred_test_adv)}')\n",
    "print(f'Test Precision: {precision_score(y_test, y_pred_test_adv, pos_label=\"Important\")}')\n",
    "print(f'Test Recall: {recall_score(y_test, y_pred_test_adv, pos_label=\"Important\")}')\n",
    "print(f'Test F1 Score: {f1_score(y_test, y_pred_test_adv, pos_label=\"Important\")}')\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, 'email_detection_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation results (before adversarial attacks):\n",
      "Validation Accuracy: 0.9466666666666667\n",
      "Validation Precision: 0.0\n",
      "Validation Recall: 0.0\n",
      "Validation F1 Score: 0.0\n",
      "\n",
      "Validation results (after adversarial attacks):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pooja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9133333333333333\n",
      "Validation Precision: 0.3333333333333333\n",
      "Validation Recall: 0.625\n",
      "Validation F1 Score: 0.43478260869565216\n",
      "\n",
      "Test results (after adversarial attacks):\n",
      "Test Accuracy: 0.9\n",
      "Test Precision: 0.35714285714285715\n",
      "Test Recall: 0.45454545454545453\n",
      "Test F1 Score: 0.4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['email_detection_ensemble_model.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Function to simulate adversarial attacks\n",
    "def simulate_adversarial_attacks(X):\n",
    "    # Placeholder function to simulate adversarial attacks (replace with actual implementation)\n",
    "    # For demonstration purposes, let's add random noise to the input features\n",
    "    noisy_X = X.toarray() + np.random.normal(0, 0.007, size=X.shape)\n",
    "    return noisy_X\n",
    "\n",
    "# Extract features and labels\n",
    "X = email_df_subset['message']\n",
    "y = email_df_subset['labels']\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = vectorizer.transform(X_val)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize the base models\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "gb = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Create an ensemble model using VotingClassifier\n",
    "ensemble_model = VotingClassifier(estimators=[\n",
    "    ('random_forest', rf),\n",
    "    ('logistic_regression', lr),\n",
    "    ('gradient_boosting', gb)\n",
    "], voting='hard')\n",
    "\n",
    "# Train the ensemble model\n",
    "ensemble_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "print(\"\\nValidation results (before adversarial attacks):\")\n",
    "y_pred_val = ensemble_model.predict(X_val_tfidf)\n",
    "print(f'Validation Accuracy: {accuracy_score(y_val, y_pred_val)}')\n",
    "print(f'Validation Precision: {precision_score(y_val, y_pred_val, pos_label=\"Important\")}')\n",
    "print(f'Validation Recall: {recall_score(y_val, y_pred_val, pos_label=\"Important\")}')\n",
    "print(f'Validation F1 Score: {f1_score(y_val, y_pred_val, pos_label=\"Important\")}')\n",
    "\n",
    "# Simulate adversarial attacks on the validation set\n",
    "X_val_adversarial = simulate_adversarial_attacks(X_val_tfidf)\n",
    "\n",
    "# Evaluate the model on the perturbed validation set\n",
    "print(\"\\nValidation results (after adversarial attacks):\")\n",
    "y_pred_val_adv = ensemble_model.predict(X_val_adversarial)\n",
    "print(f'Validation Accuracy: {accuracy_score(y_val, y_pred_val_adv)}')\n",
    "print(f'Validation Precision: {precision_score(y_val, y_pred_val_adv, pos_label=\"Important\")}')\n",
    "print(f'Validation Recall: {recall_score(y_val, y_pred_val_adv, pos_label=\"Important\")}')\n",
    "print(f'Validation F1 Score: {f1_score(y_val, y_pred_val_adv, pos_label=\"Important\")}')\n",
    "\n",
    "# Simulate adversarial attacks on the test set\n",
    "X_test_adversarial = simulate_adversarial_attacks(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model on the perturbed test set\n",
    "print(\"\\nTest results (after adversarial attacks):\")\n",
    "y_pred_test_adv = ensemble_model.predict(X_test_adversarial)\n",
    "print(f'Test Accuracy: {accuracy_score(y_test, y_pred_test_adv)}')\n",
    "print(f'Test Precision: {precision_score(y_test, y_pred_test_adv, pos_label=\"Important\")}')\n",
    "print(f'Test Recall: {recall_score(y_test, y_pred_test_adv, pos_label=\"Important\")}')\n",
    "print(f'Test F1 Score: {f1_score(y_test, y_pred_test_adv, pos_label=\"Important\")}')\n",
    "\n",
    "# Save the ensemble model\n",
    "joblib.dump(ensemble_model, 'email_detection_ensemble_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9066666666666666\n",
      "Test Precision: 0.4117647058823529\n",
      "Test Recall: 0.6363636363636364\n",
      "Test F1 Score: 0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['email_detection_model.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "def simulate_adversarial_attacks(X):\n",
    "    # Placeholder function to simulate adversarial attacks (replace with actual implementation)\n",
    "    # For demonstration purposes, let's add random noise to the input features\n",
    "    noise = np.random.normal(0, 0.007, size=X.shape)\n",
    "    noisy_X = X.toarray() + noise  # Convert X to array before adding noise\n",
    "    return noisy_X\n",
    "\n",
    "# Extract features and labels\n",
    "X = email_df_subset['message']\n",
    "y = email_df_subset['labels']\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = vectorizer.transform(X_val)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Adversarial Training\n",
    "# Generate adversarial examples\n",
    "X_train_adversarial = simulate_adversarial_attacks(X_train_tfidf)\n",
    "# Augment training data with adversarial examples\n",
    "X_train_augmented = np.vstack([X_train_tfidf.toarray(), X_train_adversarial])\n",
    "y_train_augmented = np.hstack([y_train, y_train])\n",
    "# Train the model with augmented data\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_augmented, y_train_augmented)\n",
    "\n",
    "# Regularization\n",
    "# Add regularization to the model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, ccp_alpha=0.1)\n",
    "\n",
    "# Model Architecture\n",
    "# Experiment with a different model architecture\n",
    "model = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)\n",
    "\n",
    "# Data Augmentation\n",
    "# Augment training data with noise addition\n",
    "X_train_noisy = X_train_tfidf.toarray() + np.random.normal(0, 0.01, size=X_train_tfidf.shape)\n",
    "X_train_augmented = np.vstack([X_train_tfidf.toarray(), X_train_noisy])\n",
    "y_train_augmented = np.hstack([y_train, y_train])\n",
    "\n",
    "# Ensemble Methods\n",
    "# Train an ensemble of models with different architectures\n",
    "model1 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model2 = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "models = [model1, model2]\n",
    "for model in models:\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Evaluation on Adversarial Examples\n",
    "# Simulate adversarial attacks on the test set\n",
    "X_test_adversarial = simulate_adversarial_attacks(X_test_tfidf)\n",
    "# Evaluate the model on the perturbed test set\n",
    "y_pred_test_adv = model.predict(X_test_adversarial)\n",
    "print(f'Test Accuracy: {accuracy_score(y_test, y_pred_test_adv)}')\n",
    "print(f'Test Precision: {precision_score(y_test, y_pred_test_adv, pos_label=\"Important\")}')\n",
    "print(f'Test Recall: {recall_score(y_test, y_pred_test_adv, pos_label=\"Important\")}')\n",
    "print(f'Test F1 Score: {f1_score(y_test, y_pred_test_adv, pos_label=\"Important\")}')\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, 'email_detection_model.pkl')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#input \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py:1262\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1260\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1263\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1264\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1265\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1267\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py:1305\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1303\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1304\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
