{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the sampled subset:\n",
      "                                              file  \\\n",
      "427616                     shackleton-s/sent/1912.   \n",
      "108773                    farmer-d/logistics/1066.   \n",
      "355471                  parks-j/deleted_items/202.   \n",
      "457837  stokley-c/chris_stokley/iso/client_rep/41.   \n",
      "124910               germany-c/all_documents/1174.   \n",
      "\n",
      "                                                  message         labels  \n",
      "427616  Message-ID: <21013688.1075844564560.JavaMail.e...  Non-Important  \n",
      "108773  Message-ID: <22688499.1075854130303.JavaMail.e...  Non-Important  \n",
      "355471  Message-ID: <27817771.1075841359502.JavaMail.e...  Non-Important  \n",
      "457837  Message-ID: <10695160.1075858510449.JavaMail.e...  Non-Important  \n",
      "124910  Message-ID: <27819143.1075853689038.JavaMail.e...  Non-Important  \n",
      "Dataset saved successfully at: C:/Users/pooja/OneDrive/Documents/sample_emails_labeled.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "data_path = 'C:/Users/pooja/OneDrive/Documents/emails.csv'\n",
    "email_df = pd.read_csv(data_path)\n",
    "\n",
    "# Sample a subset of the data if needed\n",
    "n_samples = 1000\n",
    "if len(email_df) > n_samples:\n",
    "    email_df_subset1 = email_df.sample(n=n_samples, random_state=42)\n",
    "else:\n",
    "    email_df_subset1 = email_df\n",
    "\n",
    "# Add numeric and descriptive 'label' columns\n",
    "def label_email(message):\n",
    "    # Placeholder logic for labeling (e.g., check for keywords)\n",
    "    if 'urgent' in message.lower() or 'important' in message.lower():\n",
    "        return 'Important'  # Example label for important emails\n",
    "    else:\n",
    "        return 'Non-Important'  # Example label for non-important emails\n",
    "\n",
    "email_df_subset1['labels'] = email_df_subset1['message'].apply(label_email)\n",
    "\n",
    "# Display the first few rows of the sampled subset with the 'labels' column\n",
    "print(\"First few rows of the sampled subset:\")\n",
    "print(email_df_subset1.head())\n",
    "\n",
    "# Define the file path where you want to save the dataset\n",
    "save_path = 'C:/Users/pooja/OneDrive/Documents/sample_emails_labeled.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "email_df_subset1.to_csv(save_path, index=False)\n",
    "\n",
    "print(\"Dataset saved successfully at:\", save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated DataFrame with additional features:\n",
      "                                         file  \\\n",
      "0                     shackleton-s/sent/1912.   \n",
      "1                    farmer-d/logistics/1066.   \n",
      "2                  parks-j/deleted_items/202.   \n",
      "3  stokley-c/chris_stokley/iso/client_rep/41.   \n",
      "4               germany-c/all_documents/1174.   \n",
      "\n",
      "                                             message         labels  \\\n",
      "0  Message-ID: <21013688.1075844564560.JavaMail.e...  Non-Important   \n",
      "1  Message-ID: <22688499.1075854130303.JavaMail.e...  Non-Important   \n",
      "2  Message-ID: <27817771.1075841359502.JavaMail.e...  Non-Important   \n",
      "3  Message-ID: <10695160.1075858510449.JavaMail.e...  Non-Important   \n",
      "4  Message-ID: <27819143.1075853689038.JavaMail.e...  Non-Important   \n",
      "\n",
      "  sender_domain  time_of_receipt  subject_length  \n",
      "0         1912.                1              22  \n",
      "1         1066.                5              25  \n",
      "2          202.                4              20  \n",
      "3           41.               14              23  \n",
      "4         1174.                4              14  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the dataset\n",
    "data_path = 'C:/Users/pooja/OneDrive/Documents/sample_emails_labeled.csv'\n",
    "email_df = pd.read_csv(data_path)\n",
    "\n",
    "# Feature Engineering\n",
    "# Extract sender email domain\n",
    "email_df['sender_domain'] = email_df['file'].apply(lambda x: x.split('/')[-1].split('@')[-1])\n",
    "\n",
    "# Extract time of receipt (hour of the day) from message content\n",
    "def extract_time_of_receipt(message):\n",
    "    time_regex = r'Date:.*?(\\d{2}:\\d{2}:\\d{2})'\n",
    "    match = re.search(time_regex, message, re.IGNORECASE)\n",
    "    if match:\n",
    "        time_str = match.group(1)\n",
    "        return pd.to_datetime(time_str).hour\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "email_df['time_of_receipt'] = email_df['message'].apply(extract_time_of_receipt)\n",
    "\n",
    "# Extract email subject length from message content\n",
    "def extract_subject_length(message):\n",
    "    subject_regex = r'Subject:(.*?)(?=\\n)'\n",
    "    match = re.search(subject_regex, message, re.IGNORECASE)\n",
    "    if match:\n",
    "        subject = match.group(1).strip()\n",
    "        return len(subject)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "email_df['subject_length'] = email_df['message'].apply(extract_subject_length)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(\"Updated DataFrame with additional features:\")\n",
    "print(email_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "\n",
      "Accuracy: 0.935\n",
      "\n",
      "Precision: [0.    0.935]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Important       0.00      0.00      0.00        13\n",
      "Non-Important       0.94      1.00      0.97       187\n",
      "\n",
      "     accuracy                           0.94       200\n",
      "    macro avg       0.47      0.50      0.48       200\n",
      " weighted avg       0.87      0.94      0.90       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pooja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\pooja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\pooja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\pooja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score\n",
    "\n",
    "# Define features and target variable\n",
    "X = email_df[['sender_domain', 'time_of_receipt', 'subject_length']]\n",
    "y = email_df['labels']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define parameter grid for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Initialize Random Forest classifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Use the best model for prediction\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average=None)\n",
    "print(\"\\nAccuracy:\", accuracy)\n",
    "print(\"\\nPrecision:\", precision)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "\n",
      "Accuracy: 0.935\n",
      "\n",
      "Precision: [0.    0.935]\n",
      "\n",
      "Recall: [0. 1.]\n",
      "\n",
      "F1-score: [0.         0.96640827]\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  0  13]\n",
      " [  0 187]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Important       0.00      0.00      0.00        13\n",
      "Non-Important       0.94      1.00      0.97       187\n",
      "\n",
      "     accuracy                           0.94       200\n",
      "    macro avg       0.47      0.50      0.48       200\n",
      " weighted avg       0.87      0.94      0.90       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pooja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\pooja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\pooja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\pooja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "# Load or define your email_df with features and labels\n",
    "# Example: email_df = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Define features and target variable\n",
    "X = email_df[['sender_domain', 'time_of_receipt', 'subject_length']]\n",
    "y = email_df['labels']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define parameter grid for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Initialize Random Forest classifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Use the best model for prediction\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average=None)\n",
    "recall = recall_score(y_test, y_pred, average=None)\n",
    "f1 = f1_score(y_test, y_pred, average=None)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"\\nAccuracy:\", accuracy)\n",
    "print(\"\\nPrecision:\", precision)\n",
    "print(\"\\nRecall:\", recall)\n",
    "print(\"\\nF1-score:\", f1)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Print Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pooja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "\n",
      "Accuracy: 0.9975062344139651\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       400\n",
      "           2       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           1.00       401\n",
      "   macro avg       0.50      0.50      0.50       401\n",
      "weighted avg       1.00      1.00      1.00       401\n",
      "\n",
      "Sender reputation scores saved to sender_reputation_scores.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pooja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\pooja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\pooja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the CSV file\n",
    "data_path = 'sample_emails_labeled.csv'\n",
    "email_df = pd.read_csv(data_path)\n",
    "\n",
    "# Feature Engineering\n",
    "\n",
    "# Extract sender domain from the 'file' column\n",
    "def extract_sender_domain(file):\n",
    "    try:\n",
    "        return file.split('/')[-1].split('@')[-1]\n",
    "    except AttributeError:\n",
    "        return 'unknown'\n",
    "\n",
    "email_df['sender_domain'] = email_df['file'].apply(extract_sender_domain)\n",
    "\n",
    "# Dummy sender reputation score based on sender domain length\n",
    "def dummy_sender_reputation(sender_domain):\n",
    "    if sender_domain == 'unknown':\n",
    "        return 0\n",
    "    # Simplified logic: shorter domains might be considered more trustworthy\n",
    "    return len(sender_domain)\n",
    "\n",
    "email_df['sender_reputation'] = email_df['sender_domain'].apply(dummy_sender_reputation)\n",
    "\n",
    "# Extract time of receipt (for example purposes, let's use a fixed dummy value)\n",
    "email_df['time_of_receipt'] = 12  # Assuming all emails are received at noon (12 PM)\n",
    "\n",
    "# Extract email subject length (if subject is present in 'message' column)\n",
    "def calculate_subject_length(message):\n",
    "    if isinstance(message, str):\n",
    "        subject = message.split('\\n')[0]  # Assuming the subject is the first line of the message\n",
    "        return len(subject)\n",
    "    return 0\n",
    "\n",
    "email_df['subject_length'] = email_df['message'].apply(calculate_subject_length)\n",
    "\n",
    "# Ensure all features are numeric\n",
    "email_df['sender_reputation'] = pd.to_numeric(email_df['sender_reputation'], errors='coerce').fillna(0)\n",
    "email_df['time_of_receipt'] = pd.to_numeric(email_df['time_of_receipt'], errors='coerce').fillna(0)\n",
    "email_df['subject_length'] = pd.to_numeric(email_df['subject_length'], errors='coerce').fillna(0)\n",
    "\n",
    "# Define features and target variable\n",
    "X = email_df[['sender_reputation', 'time_of_receipt', 'subject_length']]\n",
    "y = email_df['labels']\n",
    "\n",
    "# Ensure target variable is numeric and handle any missing values\n",
    "y = pd.to_numeric(y, errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model Tuning\n",
    "\n",
    "# Define parameter grid for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Initialize Random Forest classifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Use the best model for prediction\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "\n",
    "# Evaluation Metrics\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"\\nAccuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the sender domains and their reputation scores to a new CSV file\n",
    "sender_reputation_df = email_df[['sender_domain', 'sender_reputation']].drop_duplicates()\n",
    "sender_reputation_df.to_csv('sender_reputation_scores.csv', index=False)\n",
    "\n",
    "print(\"Sender reputation scores saved to sender_reputation_scores.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
